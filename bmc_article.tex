%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
\usepackage{amsthm,amsmath}
%\RequirePackage{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
%\RequirePackage{hyperref}
% \usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails
\usepackage{graphicx}
\usepackage{cite}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%From Notebook%%%%%%%%%%%%%%%%%%%%%%%%%%

    \usepackage{graphicx} % Used to insert images
    \usepackage{adjustbox} % Used to constrain images to a maximum size
    \usepackage{color} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    % \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{ulem} % ulem is needed to support strikethroughs (\sout)




    \definecolor{orange}{cmyk}{0,0.4,0.8,0.2}
    \definecolor{darkorange}{rgb}{.71,0.21,0.01}
    \definecolor{darkgreen}{rgb}{.12,.54,.11}
    \definecolor{myteal}{rgb}{.26, .44, .56}
    \definecolor{gray}{gray}{0.45}
    \definecolor{lightgray}{gray}{.95}
    \definecolor{mediumgray}{gray}{.8}
    \definecolor{inputbackground}{rgb}{.95, .95, .85}
    \definecolor{outputbackground}{rgb}{.95, .95, .95}
    \definecolor{traceback}{rgb}{1, .95, .95}
    % ansi colors
    \definecolor{red}{rgb}{.6,0,0}
    \definecolor{green}{rgb}{0,.65,0}
    \definecolor{brown}{rgb}{0.6,0.6,0}
    \definecolor{blue}{rgb}{0,.145,.698}
    \definecolor{purple}{rgb}{.698,.145,.698}
    \definecolor{cyan}{rgb}{0,.698,.698}
    \definecolor{lightgray}{gray}{0.5}

    % bright ansi colors
    \definecolor{darkgray}{gray}{0.25}
    \definecolor{lightred}{rgb}{1.0,0.39,0.28}
    \definecolor{lightgreen}{rgb}{0.48,0.99,0.0}
    \definecolor{lightblue}{rgb}{0.53,0.81,0.92}
    \definecolor{lightpurple}{rgb}{0.87,0.63,0.87}
    \definecolor{lightcyan}{rgb}{0.5,1.0,0.83}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}

\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}




    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    % \hypersetup{
    %   breaklinks=true,  % so long urls are correctly broken across lines
    %   colorlinks=true,
    %   urlcolor=blue,
    %   linkcolor=darkorange,
    %   citecolor=darkgreen,
    %   }
    % Slightly bigger margins than the latex defaults

    % \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \def\includegraphic{}
% \def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs
\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \title{Materials Knowledge Systems in Python - A Data Science Tool for Accelerated Development of Hierarchical Materials}

\title{Materials Knowledge Systems in Python - A Data Science Framework for Accelerated Development of Hierarchical Materials}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},
   email={davidbrough.net}   % email address
]{\inits{DB}\fnm{David B} \snm{Brough}}
\author[
   addressref={aff2},
   email={http://wd15.github.io/about}
]{\inits{DW}\fnm{Daniel} \snm{Wheeler}}
\author[
   addressref={aff1,aff3},
   corref={aff1},
   email={surya.kalidindi@me.gatech.edu}
]{\inits{SRK}\fnm{Surya R.} \snm{Kalidindi}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{School of Computational Science and Engineering, Georgia Institute of Technology}, % university, etc
%   \street{},                     %
  \postcode{30332},                                % post or zip code
  \city{Atlanta},                              % city
  \cny{USA}                                    % country
}
\address[id=aff2]{%
  \orgname{Materials Science and Engineering Division, Material Measurement Laboratory, National Institute of Standards and Technology},
%   \street{D\"{u}sternbrooker Weg 20},20899
  \postcode{20899},
  \city{Gaithersburg},
  \cny{USA}
}
\address[id=aff3]{%
  \orgname{George W. Woodruff School of Mechanical Engineering, Georgia Institute of Technology},
%   \street{},                     %
  \postcode{30332},                                % post or zip code
  \city{Atlanta},                              % city
  \cny{USA}                                    % country
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
% \note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract

To Do

% The modern advent of information technology has facilitated massive electronic
% collaborations (e-collaborations) that have lead to significant advances in several
% domains including the discover of the Higg's boson, the sequencing of the human genome,
% the Polymath project, the monitoring of species migration and numerous open source software
% projects. E-collaborations allow experts from complementary domains to create close
% collaborations regardless of spatial and temporal distances. E-collaborations
% require cyber-infrastructure that allow members to generated, analyzed, disseminated,
% and consumed information [10]. Open source cyber-infrastructure eliminates
% collaboration hurdles due to software licenses, and can help foster truly
% massive e-collaborations.

% Customized materials design has great potential for impacting virtually all emerging
% technologies, with significant economic consequences [15, 16, 12, 13, 17, 18, 19,
% 20, 21, 22, 23]. However, materials design (including the design of a manufactur-
% ing process route) resulting in the combination of properties desired for a specific
% application is a highly challenging inverse problem due to hierarchical nature of
% materials structure. Material properties are controlled by the hierarchical internal
% structure (over multiple length scales which spans from atomic to macroscopic) as
% well as coupled physical phenomena which can occur at different timescales at each
% of the hierarchical length scales. Characterization of the structure at each of these
% different length scales is often in the form of images which come from different
% experimental/computational techniques resulting in highly heterogeneous data. As a
% result, tailoring the material hierarchical structure to yield desired combinations of
% properties or performance characteristics is enormous difficult.

% There is a critical need for customized analytics that take into account
% the stochastic nature of these data at multiple length scales in order to extract
% relevant and transferable knowledge. Data driven Process-Structure-Property (PSP)
% linkages provide systemic, modular and hierarchical protocols for community engagement
% (i.e., several people making complementary or overlapping contributions to the
% overall curation of materials knowledge). Computationally cheap PSP linkages exact
% valuable materials knowledge from these heterogeneous datasets and provide a
% format that is usable and valuable for design and manufacturing experts.

% The Materials Knowledge Systems in Python project (PyMKS) is the first open
% source materials data science tool that can be used to create high value PSP linkages
% for hierarchical materials that can be leveraged by experts in materials science and
% engineering, manufacturing, and data science communities, and is essential
% component in the cyber-infrastructure needed to realize a modern accelerated
% materials innovation ecosystems. The on going work demonstrates the versatility
% of PyMKS.

% \parttitle{First part title} %if any
% Text for this section.

% \parttitle{Second part title} %if any
% Text for this section.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{TBD}
% \kwd{article}
% \kwd{author}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%
\section{Introduction}

% David - the start is a little weak. Logically, you are better off starting with the need for collaborations - i.e., disciplinary siloed efforts versus cross-disciplinary integrated efforts. Although, the virtues of collaborations have been known for a very long time, there were no mechanisms to scale these up dramatically in intensity and numbers. With the advent of modern information technology - the landscape has changed significantly - with the e-collaborations it is now possible to do this. Discuss the main elements of e-collaborations broadly and point out that open source and open access code repositories are a foundational element for an e-collaboration platform. Talk also about the critical role they play in digital capture, curation, and dissemination of workflows - which is central to community adoption and engagement (e.g., e-Science gateways).




% After this broad introduction, you can then narrow down your focus to code repositories and workflows - talk about the current challenges broadly.

% Then move the discussion to materials science domain where this presents a major new opportunity ...

%% May want to integrate this.
Current practices for developing tools and infrastructure used in multiscale materials design, development, and deployment are generally highly localized (sometimes even within a single organization) resulting in major inefficiencyies (duplication of effort, lack of code review, not engaging the right talent for the right task, etc.). Although it is well known that the pace of discovery and innovation  significantly increases with effective collaboration \cite{sawhney2005collaborating, edwards2009open, bayne2008interdisciplinary, boudreau2010open}, scaling such efforts to large heterogeneous communities such as those engaged in materials innovation has been very difficult.

The advent of information technology has facilitated massive electronic collaborations (generally referred to as e-collaborations) that have lead to significant advances in several domains including the discovery of the Higg's boson \cite{aad2012observation}, the sequencing of the human genome \cite{lander2001initial}, the Polymath project \cite{cranshaw2011polymath}, the monitoring of species migration \cite{dickinson2010citizen, hochachka2012data} and numerous open source software projects. E-collaborations allow experts from complementary domains to create highly productive collaborations that transcend geographical, temporal, cultural, and organizational distances. E-collaborations require a supporting cyber-infrastructure that allows team members to generate, analyze, disseminate, access, and consume information at dramatically increased pace and/or quantity \cite{atkins2003revolutionizing}. A key element of this emerging cyber-infrastructure is open source software as it eliminates collaboration hurdles due to software licenses and can help foster truly massive e-collaborations. In other words, even with collaborations involving proprietary data, open source cyber-infrastructure provide a common language that can facilitate e-collaborations with large numbers of team members (could even become a community effort).

Several recent national and international initiatives \cite{anderson2011report, MGIwhite, MGI2014} have been launched with the premise that the adoption and utilization of modern data science and informatics toolsets offers a new opportunity to accelerate dramatically the design and deployment cycle of new advanced materials in commercial products. More specifically, it has been recognized that innovation cyber-ecosystems are needed to allow experts from the materials science and engineering, design and manufacturing, and data science domains to collaborate effectively. The challenge in integrating these traditionally disconnected communities comes from the vast differences in how knowledge is captured, curated, and disseminated in these communities \cite{kalidindi2015data}. More specifically, knowledge systems in the materials field are rarely captured in a digital form. In order to create a modern materials innovation ecosystem, it is imperative that we design, develop, and launch novel collaboration platforms that allow automated distilling of materials knowledge from large amounts of heterogeneous data acquired through customized protocols that are necessarily diverse (elaborated next). It is also imperative that this curated materials knowledge is presented to the design and manufacturing experts in highly accessible (open) formats.

Customized materials design has great potential for impacting virtually all emerging technologies, with significant economic consequences \cite{ward2012materials, allison2006integrated, MGIwhite, MGI2014, allison2011integrated, olson2000designing, national2008integrated, schmitz2012integrative, robinson2013tms, allisonintegrated, TMSfieldstudy}. However, materials design (including the design of a manufacturing process route) resulting in the combination of properties desired for a specific application is a highly challenging inverse problem due to the hierarchical nature of materials internal structure. Material properties are controlled by the hierarchical internal structure (over multiple length scales which spans from atomic to macroscopic) as well as coupled physical phenomena which can occur at different timescales at each of the hierarchical length scales. Characterization of the structure at each of these different length scales is often in the form of images which come from different experimental/computational techniques resulting in highly heterogeneous data. As a result, tailoring the material hierarchical structure to yield desired combinations of properties or performance characteristics is enormously difficult. Figure \ref{fig:length_scales} provides a collection of materials images depicting material structures at different length scales, which are generally acquired using diverse protocols and are captured in equally diverse formats.

\begin{figure}
    \includegraphics[scale=.23]{fig/lengthScales1.png}
    \caption{Heirarchical Materials structure at multiple length scales
      a). Simulated graphene crystalline structure. b). Simulated fivefold icosahedral Al-Ag quasicrystals. c).High resolution electron microscopy image of delamination cracks in h-BN particles subjected to compressive stress in the (0001) planes (within a silicon nitride particulate-reinforced silicon carbide composite. d). Electron diffraction pattern of an icosahedral Zn-Mg-Ho quasicrystal. e). Cross-polarised light image of spherulites in in poly-3-hydroxy butyrate (PHB) f). Cast iron with magnesium induced spheroidised graphite. g). SEM micrograph of a taffeta textile fragment h). Optical microscopy image of a cross-section of an aluminium casting  i). X-ray tomography image of open cell polyurethane foam. Images courtesy of Core-Materials \cite{coreMaterials}.}
  \label{fig:length_scales}
\end{figure}

While the generation (from experiments and computer simulations) and dissemination of datasets consisting of heterogeneous images are necessary elements in a modern materials innovation ecosystem, there is an equally critical need for customized analytics that take into account the stochastic nature of these data at multiple length scales in order to extract high value, transferable, knowledge. Data-driven Process-Structure-Property (PSP) linkages \cite{kalidindi2015hierarchical} provides a systemic, modular, and hierarchical framework for community engagement (i.e., several people making complementary or overlapping contributions to the overall curation of materials knowledge). Computationally cheap PSP linkages also communicate effectively the curated materials knowledge to design and manufacturing experts in highly accessible formats.

The Materials Knowledge Systems in Python project (PyMKS) is the first open source materials data analytics toolkit that can be used to create high value PSP linkages for hierarchical materials in large scale efforts driven and directed by an entire community of users. In this regard, it could be a foundational element of the cyber-infrastructure needed to realize a modern materials innovation ecosystem.

\section{Current Materials Innovation Ecosystem}

Open access materials databases and computational tools are critical components of the cyber-infrastructure needed to curate materials knowledge through effective e-collaborations \cite{bhat2015strategy}. Several materials science open source computational toolsets and databases have emerged in recent years to help realize the vision outlined in the Materials Genome Initiative (MGI) and the Integrated Computational Materials Engineering (ICME) paradigm \cite{ward2012materials, allison2006integrated, MGIwhite, MGI2014, allison2011integrated, olson2000designing, national2008integrated, schmitz2012integrative, robinson2013tms, allisonintegrated, TMSfieldstudy}. Yet, the creation and adoption of a standard materials taxonomy and database schema has not been established due to the unwieldy size of material descriptors and heterogeneous data. Additionally, the coupled physical phenomena that govern material properties is too complex to model all aspects of a material simultaneously using a single computational tool. Consequently, current practices have resulted in the development of computation tools and databases with a narrow focus on specific length/structure scales, material classes, or properties.

NIST Data Gateway contains over 100 free and paid query-able web-based materials databases. These databases contain atomic structure, thermodynamics, kinetics, fundamental physical constants, x-ray spectroscopy, among other features \cite{NISTgateway}. NIST DSpace provides a curation of links to several materials community databases \cite{nist2015dspace}. NIST Materials Data Curation Systems (MDCS) is a general online database that aims to facilitate the capturing, sharing, and transforming of materials data \cite{NISTDCS}. Open Quantum Materials Database (OQMD) is an open source data repository for phase diagrams and electronic ground states computed using density functional theory \cite{saal2013materials}. MatWeb is a database containing materials properties for over 100,000 materials \cite{matweb}.
Atomic FLOW of Materials Discovery (AFLOW) databases millions of materials and properties and hosts computational tools that can be used for atomic simulations \cite{curtarolo2012aflow}. The Materials Project (and the tool pyMatgen) \cite{ong2013python, jain2013commentary} provides open web-based access to computed information on known and predicted materials as well as analysis tools for electronic band structures. The Knowledgebase of Interatomic Models (OpenKIM) hosts open source tools for potentials for molecular simulation of materials \cite{kim2010project}. PRedictive Integrated Structural Materials Science (PRISMS) hosts a suite of ICME tools and datastorage for the metals community focused on microstructure evolution and mechanical properties \cite{prism}.

SPPARKS Kinetic Monte Carlo Simulator (SPPARKS) is a parallel Monte Carlo code for on-lattice and off-lattice models \cite{plimpton2012spparks}. MOOSE is a parallel computational framework for coupled systems of nonlinear equations \cite{gaston2009moose}. Dream3D is a tool used for synthetic microstructures generation, image processing and mesh creation for finite element \cite{groeber2014dream}.

While there exits a sizable number of standard analytics tools \cite{littell2006sas, seabold2010statsmodels, pedregosa2011scikit, albanese2012mlpy, goodfellow2013pylearn2, mckinney2012python, muller2014pystruct, demvsar2004orange, abadi2016tensorflow, van2014scikit}, none of them are tailored to create PSP linkages from materials structure image data and their associated properties. PyMKS aims to seed and nurture an emergent user group in the materials data analytics for establishing homogenization and localization (PSP) linkages by leveraging open source signal processing and machine learning packages in Python. An overview of the PyMKS project accompanied with several examples is presented here. This paper is a call to others interested in participating in this open science activity.

\section{Theoretical Foundations of Materials Knowledge Systems}

Material properties are controlled by their internal structure and the diverse physical phenomena occurring at multiple time and length scales. Generalized composite theories \cite{hill1963elastic, hashin1983analysis} have been developed for hierarchical materials exhibiting well separated length scales in their internal structure. Generally speaking, these theories either address homogenization (i.e., communication of effective properties associated with the structure at a given length scale to a higher length scale) or localization (i.e., spatiotemporal distribution of the imposed macroscale loading conditions to the lower length scale). Consequently, homogenization and localization are the essential building blocks in communicating the salient information in both directions between hierarchical length/structure scales in multiscale materials modeling. It is also pointed out that localization is significantly more difficult to establish, and implicitly provides a solution to homogenization.

The most sophisticated composite theory available today that explicitly accounts for the full details of the material internal structure (also simply referred as microstructure) comes from the use of perturbation theories and Green's functions \cite{brown1955solid, hill1963elastic, kroner1986statistical, kroner1977bounds, kroner1972statistical, etingof1993representations, adams1998mesostructure, fullwood2008strong, torquato2013random, li2006quantitative, milhans2011prediction, adams2013microstructure, garmestani2001statistical}. In this formalism, one usually arrives at a series expansion for both homogenization and localization, where the individual terms in the series involve convolution integrals with kernels based  on  Green's functions. This series expansion was refined and generalized by Adams and co-workers \cite{adams2005finite, adams2013microstructure, binci2008new} through the introduction of the concept of a microstructure function, which conveniently separates each term in the series into a physics-dependent kernel (based on Green's functions) and a microstructure-dependent function (based on the formalism of n-point spatial correlations \cite{etingof1993representations, adams1998mesostructure, fullwood2008strong, torquato2013random, li2006quantitative, milhans2011prediction}).

 Materials Knowledge Systems (MKS) \cite{landi2010multi, kalidindi2010novel, yabansu2014calibrated, al2012multi, kalidindi2011microstructure, gupta2015structure,  cceccen2014data} complements these sophisticated physics-based materials composite theories with a modern data science approach to create a versatile framework for extracting and curating multiscale PSP linkages. More specifically, MKS employs a discretized version of the composite theories mentioned earlier to gain major computational advantages. As a result, highly adaptable and templatable protocols have been created and used successfully to extract robust and versatile homogenization and localization metamodels with impressive accuracy and broad applicability over large microstructure spaces.

The MKS framework is based on the notion of a microstructure function.
The microstructure function provides a framework to represent material
structure terms of quantities such as phase identifiers, lattice
orientation, chemical composition, defect types and densities,
among others refered to as local states. The microstructure function,
$m_j \left(h; s\right)$, represents a
probability distribution for the given local state, $h \in H$, at
each position, $s \in S$, in a given microstructure,
$j$~\cite{niezgoda2013novel, niezgoda2011understanding,
qidwai2012estimating, niezgoda2010optimized}. The
introduction of the local state space $H$ (i.e., the complete set of
all potential local states) provides a consolidate variable space for
combining the diverse attributes (often a combination of
scalar and tensor quantities) needed to describe the
local states in the material structure.
The MKS framework requires a discretized description of $m_j$, which is
denoted here as $m_j\left[h; s\right]$, where the
$\left[\cdot;\cdot\right]$ represent the discretized space (in contrast
to $\left(\cdot;\cdot\right)$, which defines the continuous space).
The ``$;$'' symbol divides indices in physical space to the right of
``$;$'' from indices in state space to the left of ``$;$''. In most
applications, $S$ is simply tessellated into voxels
on a regular (uniform) grid such that the position can
be given by $s\rightarrow i,j,k$ in three dimensions.

As noted earlier, the local state space in most advanced materials is
likely to demand sophisticated representations. In prior work
\cite{yabansu2014calibrated, yabansu2015representation,
brough2016microstructure}, it was found that spectral
representations on functions on the local state space offered many
advantages both in compact representation as well as in reducing the
computational cost. In such cases, $h$ indexes the spectral basis
functions employed. The selection of these functions depends on the
nature of local state descriptors. Examples include: (i) the primitive
basis (or indicator functions) used to represent simple tessellation
schemes \cite{landi2010multi, kalidindi2010novel, al2012multi,
kalidindi2011microstructure, gupta2015structure, cceccen2014data,
niezgoda2013novel, niezgoda2011understanding, cecen2016versatile},
(ii) generalized spherical harmonics used to represent functions over
the orientation space \cite{yabansu2014calibrated,
yabansu2015representation}, and (iii) Legendre polynomials used to
represent functions over the concentration space
\cite{brough2016microstructure}.

\subsection{Homogenization}

Comparing different microstructures is quite difficult even after
expressing them in convenient discretized descriptions mainly due to
the lack of a reference point or a natural origin for the index $s$ in
the tessellation of the microstructure volume. Yet the relative
spatial distributions of the local states provide a valuable
representation of the microstructure that can be used effectively to
quantify the microstructure and compare it with other microstructures
in robust and meaningful ways \cite{niezgoda2011understanding,
niezgoda2010optimized, niezgoda2013novel, cceccen2014data,
cecen2016versatile}. The lowest order of spatial correlations comes
in the form of 2-point statistics and can be computed as a correlation
of a microstructure function such that
\begin{equation}\label{eq:stats}
    f_j[h, h'; r] = \frac{1}{\Omega_j\left[r\right]}
    \sum_{s} m_j[h; s] m_j[h'; s +  r]
\end{equation}
\begin{figure}
    \centering
    \includegraphics{fig/stats_micro_example.png}
    \caption{The microstructure function (also referred to as the discretized microstructure) for a two phase composite material.
    The enumerated with a spatial index $s$. Discrete vectors $r$ describe the relative positions between different spatial locations.}
    \label{fig:stats}
\end{figure}
where $r$ is a discrete spatial vector within the voxelated domain
specified by $s$, $f_j[h, h'; r]$ is one set of 2-point statistics for
the local stats $h$ and $h'$ and $\Omega_j\left[r\right]$ is a
normalization factor that depends on
$r$~\cite{cecen2016versatile}. The subscript $j$ refers to a sample
microstructure used for analysis (i.e. each $j$ could refer to a
microstructure image). The physical interpretation of the 2-point
statistics is explained in Fig. \ref{fig:stats} with a highly
simplified two-phase microstructure (the two phases are colored white
and gray). If the the primitive basis is used to discretize both the
spatial domain and the local state space then $f_j[h, h'; r]$ can be
interpreted as the probability of finding local states $h$ and $h'$ at
the tail and head of the vector $r$, respectively.

2-Point statistics provide a meaningful representation of the
microstructure, but create an extremely large feature space that often
contains redundant information. Dimensionality reduction can be used
to create low dimensional microstructure descriptors from the sets of
spatial correlations (based on different selections of $h$ and $h'$)
with principal component analysis (PCA). The PCA dimensionality
reduction can be mathematically expressed as
\begin{equation} \label{eq:struc}
    f_j\left[l\right] \approx \sum_{k\in K} \mu_j\left[k\right]
    \phi\left[k,l\right] + \overline{f[l]}
\end{equation}
In Eq. \ref{eq:struc}, $f_j\left[l\right]$ are the low rank
approximations of 2-point statistics, where the
$f_j\left[h, h'; r\right]$ indices from Eq. \ref{eq:stats}
are represented as a vector with single index given by
$f_j\left[l\right]$ where $l$ is a unique integer for every combination
of $h$, $h'$ and $r$. The $\mu_j[k]$ are low dimensional microstructure
descriptors (the transformed 2-point statistics) or principal component
scores (PC scores). The $\phi\left[k, l\right]$ are the calibrated
principle components (PCs) and the $\overline{f[l]}$ are the mean
values  from the calibration ensemble of $f_j\left[l\right]$ for each
$l$. The $k \in K$ indices refer to the $\mu_j\left[k\right]$ in
decreasing order of significance and are independent of $l$, $l'$ and
$r$. The main advantage of this approach is that the
$f_j\left[l\right]$ can be reconstructed to sufficient fidelity with
only a small subset of $\mu_j\left[k\right]$
\cite{hotelling1933analysis}.

After obtaining the needed dimensionality reduction in the
representation of the material structure, machine learning models can
be used to create homogenization PSP linkages of interest.
As an example, a generic homogenization linkage can be expressed as
\begin{equation} \label{eq:hom}
    p_j^{\text{eff}} = \mathcal{F}(\mu_j[k])
\end{equation}
In Eq. \ref{eq:hom}, $p_j^{\text{eff}}$ is the effective materials
response (reflecting an effective property in structure-property
linkages or an evolved low dimensional microstructure descriptor in
process-structure linkages), and $\mathcal{F}$ is a machine learning
function that links $\mu_j[k]$ to $p_j^{\text{eff}}$.

\subsection{Localization}

MKS Localization linkages are significantly more complex than the
homogenization linkages. These are usually expressed in the same
series forms that are derived in the general composite theories, while
employing discretized kernels based on Green's functions
\cite{brown1955solid, hill1963elastic, kroner1986statistical,
  kroner1977bounds, kroner1972statistical, etingof1993representations,
  adams1998mesostructure, fullwood2008strong, torquato2013random,
  li2006quantitative, milhans2011prediction, adams2013microstructure,
  garmestani2001statistical}. Mathematically, the MKS localization
linkages are expressed as
\begin{multline}
    \label{eq:series}
    p_j[s] = \sum_{h; r} \alpha[h; r] m_j[h; s - r] + \sum_{h, h'; r, r'}
    \alpha[h, h'; r, r'] m_j[h; s - r] m_j[h'; s - r'] + ...
\end{multline}
In Eq. \ref{eq:series}, $p_j[s]$ is the spatially resolved (localized)
response field (e.g. a response variable such as stress or strain
rate in a structure-property linkage, or an evolved microstructure
function in a process-structure linkage), and $\alpha[h; r]$ are
the Green's function based discretized influence kernels. These
digital kernels are calibrated using regression methods
\cite{al2012multi, kalidindi2010novel, landi2010multi,
  yabansu2014calibrated, yabansu2015representation,
  brough2016microstructure}.

Fig. \ref{fig:workflows} provides a schematic overviews of
the MKS homogenization and localization workflows. More detailed
explanations on the MKS homogenization and localization linkages
can be found in prior literature \cite{landi2010multi, kalidindi2010novel,
yabansu2014calibrated, al2012multi, kalidindi2011microstructure,
gupta2015structure, brough2016microstructure, cceccen2014data,
niezgoda2013novel, niezgoda2011understanding, cecen2016versatile}.

\begin{figure}[h!]
  \caption{
     The MKS Homogenization workflow (left) consists of four steps. 1.
     Discretize the raw microstructure with the microstructure function.
     2. Compute 2-point statistics using local states (Eq. \ref{eq:stats}).
     3. Create low dimensional microstructure descriptors using dimensionality
     reduction technques (Eq. \ref{eq:struc}).
     4. Use machine learning model to establish a linkage with low dimensional 
     microtructure descriptors. (Eq. \ref{eq:hom}).
     The MKS Localization workflow (right) constists of 2 steps. 
     1. Discretize the raw microstructure with the microstructure function.
     2. Calibrated physics-based kernels (Eq. \ref{eq:series}).}
    \includegraphics[scale=.22]{fig/mks_workflows.png}
  \label{fig:workflows}
\end{figure}


\section{Materials Knowledge Systems in Python}

PyMKS is an object-oriented numerical implementation to the MKS theory
developed in the literature~\cite{kalidindi2010novel}. It provides a
high-level, computational efficient framework to implement data
pipelines for classification, cataloging and quantifying materials
structures for PSP relationships. PyMKS is written in Python, a
natural choice for scientific computing due to its ubiquitous use
among the data science community as well as many other favorable
attributes~\cite{perez2011python}. PyMKS is licensed under the
permissive MIT license \cite{MIT} which allows for unrestricted
distribution in commercial and non-commercial systems.

\subsection{Core Functionality}


PyMKS consists of four main components including a set of tools to
compute 2-point statistics, tools for both homogenization and
localization linkages and tools for discretizing the microstructure. In
addition, PyMKS has modules for generating data sets using
conventional numerical simulations and a module for custom
visualization of microstructures. PyMKS builds on Scikit-Learn's
pipelining methodology to create materials specific machine learning
models. This is a high level system for combining
multiple data and machine learning transformations into a single
customizable pipeline with only minimal required code. This approach
makes cross-validation and parameter searches simple to implement and
avoids the complicated book keeping issues associated with training,
testing and validating data pipelines in machine learning.

The starting point for an MKS homogenization analysis is to use
2-point statisics as outlined in Eq.~\ref{eq:stats} and provided in
PyMKS by the \texttt{MKSStructureAnalysis} object, which calculates
the objective low dimensional structure descriptors, $\mu_j[k]$. The
default dimensionality reduction technique is PCA, but any model that
uses the \texttt{transform\_fit} or a ``transformer'' object can be
substituted. After calculating the descriptors, the
\texttt{MKSHomogenizationModel} is used to create linkages between the
$\mu_j[k]$ and the effective material response, $p_j^{\text{eff}}$,
as indicated in Eq.~\ref{eq:hom}. The default machine learning
algorithm is a polynomial regression, but any estimator with the
\texttt{fit} and \texttt{predict} methods can be substitued to create
the linkages between $\mu_j[k]$ and $p_j^{\text{eff}}$.

The \texttt{MKSLocalizationModel} object provides the MKS localization
functionality. It calibrates the first order influence kernels
$\alpha[h; r]$ used to predict local materials responses, $p_j[s]$, as
outlined in Eq.~\ref{eq:series}. The calibration of the influence
kernels is achieved using a variety of linear regression techniques
described in numerous previous studies~\cite{landi2010multi,
kalidindi2010novel, yabansu2014calibrated, brough2016microstructure}.
The \texttt{MKSLocalizationModel} object uses \texttt{fit} and
\texttt{predict} methods to follow the standard interface for a
Scikit-learn estimator object.

To use either the homogenization or the localization models in PyMKS,
the microstructure first needs to be represented by a microstructure
function, $m_j\left[h, s\right]$. The \texttt{bases} module in PyMKS
contains four transformer objects for generating the
$m_j\left[h,s\right]$ using a varietly of discretization
methods~\cite{landi2010multi, kalidindi2010novel,
yabansu2014calibrated, al2012multi, kalidindi2011microstructure,
gupta2015structure, cceccen2014data, brough2016microstructure}.
These four objects can be thought of as materials specific
extension to the feature extraction
module in Scikit-Learn. A \texttt{PrimitiveBasis} object uses
indicator (or hat) functions and is well suited for microstructures
that have discrete local states (e.g., distinct thermodynamic
phases). The \texttt{LegendreBasis} and \texttt{FourierBasis} objects
create spectral representations of microstucture functions defined on
nonperiodic and periodic continuous local state spaces,
respectively. For example, functions over a range of chemical
compositions can be described using \texttt{LegendreBasis}, while
functions over orientations in two-dimensional space can be described
using \texttt{FourierBasis}. Furthermore, \texttt{GSHBasis} creates
compact spectral representations for functions over lattice
orientation space (such as those needed to describe polycrystalline
microstructures)~\cite{ kalidindi2006spectral, shaffer2010building,
knezevic2010deformation, al2010spectral, duvvuru2007application,
li2003evolution, li2005texture, li2007processing, li2005processing,
creuziger2014crystallographic, sundararaghavan2008multi,
sundararaghavan2007linear}.

PyMKS contains modest data generation tools (in the \texttt{datasets}
module) that are used in both the PyMKS examples and the PyMKS test
suite. The \texttt{MicrostructureGenerator} object creates stochastic
microstructures using digital filters. This assists users in creating
PyMKS workflows even when data is unavailable. PyMKS has objects for
generating sample data from both a spinodal decomposition simulation
(using the \texttt{CahnHilliardSimulation} object) and a linear
elasticity simulation (using the \texttt{ElasticFESimulation}
object). PyMKS comes with custom functions for visualizing
microstructures in elegant ways (in the \texttt{tools} module). These
are are used extensively in the PyMKS example notebooks to minimize
incidental code associated with visualization.

\subsection{Underlying Technologies}

PyMKS is built upon the highly optimized Python packages
NumPy~\cite{van2011numpy}, SciPy~\cite{jones2014scipy}, and
Scikit-learn~\cite{pedregosa2011scikit}. NumPy arrays are the primary
data structure used throughout PyMKS and provide the basic vector and
matrix manipulation operations. SciPy's signal processing and
numerical linear algebra functions are used to calibrate models and
generate synthetic data. PyMKS is highly integrated with Scikit-learn
and mimics its simple API in order to leverage from Scikit-learn's
data pipeling methodology for machine learning and data
transformations. In addition, PyMKS uses the Pytest framework to
automate execution of the test suite~\cite{pytest2016}.

Optional packages that can be used with PyMKS include Simple Finite
Elements in Python (SfePy)~\cite{cimrman2014sfepy}, the python wrapper
for the FFTW library (pyFFTW)~\cite{frigo1998fftw} and the plotting
package Matplotlib~\cite{hunter2007matplotlib}. SfePy is used to
simulate linear elasticity to create sample response field
data. PyFFTW is a hightly optimized Fast Fourier Transform library
that enhances the efficiency of PyMKS and enables parallel
computations in PyMKS. Matplotlib is used to generate custom
microstructure visualizations.

\subsection{Development Practices}

PyMKS leverages from existing tools, standards and web resources
wherever possible. In particular the developers are an open community
that use GitHub for issue tracking and release management
(see~\url{https://github.com/materialsinnovation/pymks}). Additionally
a Google group is used as a public forum to discuss the project
development, support and announcements
(see~\url{pymks-general@googlegroups.com}). The Travis CI continuous
integration tool is used to automate running the test suite for
branches of the code stored on GitHub. Code standards are maintained
by following the Python PEP8 standards and by reviewing code using
pull requests on GitHub. Detailed administrative guidelines are
outlined in the \texttt{ADMINISTRATA.md} document and potential
developers are encouraged to follow them.

\section{Examples of Homogenization and Localization with PyMKS}

Here a demonstration of the MKS homogenization and localization
workflows as shown in Fig. \ref{fig:workflows} are presented
using PyMKS. Additional workflow examples can be found on the
PyMKS website \url{pymks.org}.

    \subsection{Prediction of Effective Stiffness using Homogenization}\label{effective-stiffness-of-composite-material}

    \subsubsection{Calibration Data Generation}\label{data-generation}

A set of periodic microstructures and their volume averaged elastic
stress values $\bar{\sigma}_{xx}$ can be generated by importing the
\texttt{make\_elastic\_stress\_random} function from
\texttt{pymks.datasets}. This function has several arguments.
\texttt{n\_samples} is the number of samples that will be generated,
\texttt{size} specifies the dimensions of the microstructures,
\texttt{grain\_size} controls the effective microstructure feature size,
\texttt{elastic\_modulus} and \texttt{poissons\_ratio} are used to
indicate the material property for each of the phases,
\texttt{macro\_strain} is the value of the applied uniaxial strain, and
the \texttt{seed} can be used to change the the random number generator
seed.

In this homogenization example, 200 samples from six
different microstructures classes with dimensions 21 x 21 were
created totaling 1,200 samples. Each of the six classes have
different microstructure feature sizes. The
\texttt{make\_elastic\_stress\_random} function will return and the
microstructures and their associated volume averaged stress values.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{pymks.datasets} \PY{k+kn}{import} \PY{n}{make\PYZus{}elastic\PYZus{}stress\PYZus{}random}

\PY{n}{sample\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{200}
\PY{n}{grain\PYZus{}size} \PY{o}{=} \PY{p}{[}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{9}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{]}
\PY{n}{n\PYZus{}samples} \PY{o}{=} \PY{p}{[}\PY{n}{sample\PYZus{}size}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{6}
\PY{n}{elastic\PYZus{}modulus} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{310}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}
\PY{n}{poissons\PYZus{}ratio} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{0.28}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
\PY{n}{macro\PYZus{}strain} \PY{o}{=} \PY{l+m+mf}{0.001}
        \PY{n}{size} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{21}\PY{p}{,} \PY{l+m+mi}{21}\PY{p}{)}

\PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{make\PYZus{}elastic\PYZus{}stress\PYZus{}random}\PY{p}{(}
    \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n}{n\PYZus{}samples}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{size}\PY{p}{,} \PY{n}{grain\PYZus{}size}\PY{o}{=}\PY{n}{grain\PYZus{}size}\PY{p}{,}
    \PY{n}{elastic\PYZus{}modulus}\PY{o}{=}\PY{n}{elastic\PYZus{}modulus}\PY{p}{,} \PY{n}{poissons\PYZus{}ratio}\PY{o}{=}\PY{n}{poissons\PYZus{}ratio}\PY{p}{,}
    \PY{n}{macro\PYZus{}strain}\PY{o}{=}\PY{n}{macro\PYZus{}strain}\PY{p}{,} \PY{n}{seed}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}

\end{Verbatim}


The microstructures can be visualized by importing \texttt{draw\_microstructures}.
Below is an instance from three of the classes.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}microstructures}

\PY{n}{X\PYZus{}examples} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{n}{sample\PYZus{}size}\PY{p}{]}
\PY{n}{draw\PYZus{}microstructures}\PY{p}{(}\PY{n}{X\PYZus{}examples}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}

\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{homogenization_stress_2D_files/homogenization_stress_2D_8_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    \subsubsection{Calibration of Homogenization Model}\label{modeling-with-mkshomogenizationmodel}

In order to make an instance of the \texttt{MKSHomogenizationModel},
an instance of a basis class must first be created to specify the discretization
methods for the microstructure microstructure function
(see Fig. \ref{fig:workflows}). For this particular example,
there are only 2 discrete phases, therefore the \texttt{PrimitiveBasis}
from \texttt{pymks.bases} will be used. The microstructure contain only two
phases denoted by 0 and 1, therefore we have two local states and our domain
is 0 to 1. An instance of the \texttt{PrimitiveBasis} with these parameters can
be used to create an instance of the \texttt{MKSHomgenizationModel} as follows.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks} \PY{k+kn}{import} \PY{n}{MKSHomogenizationModel}
\PY{k+kn}{from} \PY{n+nn}{pymks.bases} \PY{k+kn}{import} \PY{n}{PrimitiveBasis}

\PY{n}{p\PYZus{}basis} \PY{o}{=} \PY{n}{PrimitiveBasis}\PY{p}{(}\PY{n}{n\PYZus{}states}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{domain}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\PY{n}{model} \PY{o}{=} \PY{n}{MKSHomogenizationModel}\PY{p}{(}\PY{n}{basis}\PY{o}{=}\PY{n}{p\PYZus{}basis}\PY{p}{,} \PY{n}{periodic\PYZus{}axes}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                               \PY{n}{correlations}\PY{o}{=}\PY{p}{[}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{]}\PY{p}{)}

\end{Verbatim}

The default pipeline used to create the homogenization linkage contains PCA and
polynomial regression objects for Scikit-Learn. Cross validation is used on
the testing data to find the optimal values (based
on the R-squared values) within a defined subspace for our model parameters
using \texttt{GridSeachCV} from \texttt{sklearn}. A dictionary
\texttt{params\_to\_tune} defines the subspace with a range for the degrees
of the polynomial and the number of principal components. For this example
\texttt{n\_components} will be varied between 2 to 11 and \texttt{degree} of
the polynomial regression will be varied between 1 to 3.
    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{sklearn.grid\PYZus{}search} \PY{k+kn}{import} \PY{n}{GridSearchCV}

\PY{n}{flat\PYZus{}shape} \PY{o}{=} \PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}\PY{p}{)} \PY{o}{+} \PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{size}\PY{p}{,}\PY{p}{)}
\PY{n}{params\PYZus{}to\PYZus{}tune} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{degree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{,}
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{12}\PY{p}{)}\PY{p}{\PYZcb{}}
\PY{n}{fit\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{X}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{\PYZcb{}}
\PY{n}{gs} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{params\PYZus{}to\PYZus{}tune}\PY{p}{,}
                  \PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{n}{fit\PYZus{}params}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{flat\PYZus{}shape}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\end{Verbatim}

% The default \texttt{score} method for the \texttt{MKSHomogenizationModel} is coefficient of determination
% (R-squared). 
% value. Let's look at the how the mean R-squared values and their
% standard deviations change, as we varied the number of
% \texttt{n\_components} and \texttt{degree}, using
% \texttt{draw\_gridscores\_matrix} from \texttt{pymks.tools}.

%     \begin{Verbatim}[commandchars=\\\{\}]

% {\color{incolor}In [{\color{incolor}12}]:} \PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}gridscores\PYZus{}matrix}

%          \PY{n}{draw\PYZus{}gridscores\PYZus{}matrix}\PY{p}{(}\PY{n}{gs}\PY{p}{,} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{degree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{score\PYZus{}label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{R\PYZhy{}Squared}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
%                                 \PY{n}{param\PYZus{}labels}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of Components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Order of Polynomial}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
% \end{Verbatim}

%     \begin{center}
%     \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{homogenization_stress_2D_files/homogenization_stress_2D_27_0.png}
%     \end{center}
%     { \hspace*{\fill} \\}

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Order of Polynomial}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{gs}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{o}{.}\PY{n}{degree}\PY{p}{)}
\PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of Components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{gs}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}\PY{o}{.}\PY{n}{n\PYZus{}components}\PY{p}{)}
\PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{R\PYZhy{}squared Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{p}{(}\PY{n}{gs}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{flat\PYZus{}shape}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

Order of Polynomial 2
Number of Components 11
R-squared Value 0.999808062591

    \end{Verbatim}

For the specified subspace it was found that a model
with a 2nd order polynomial and 11 principal components had the 
highest R-squared value. The results over the whole subspace
explored with \texttt{GridSeachCV} can be visualized using
\texttt{draw\_grid\_scores}.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}gridscores}

\PY{n}{gs\PYZus{}deg\PYZus{}1} \PY{o}{=} \PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{gs}\PY{o}{.}\PY{n}{grid\PYZus{}scores\PYZus{}}
            \PY{k}{if} \PY{n}{x}\PY{o}{.}\PY{n}{parameters}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{degree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}
\PY{n}{gs\PYZus{}deg\PYZus{}2} \PY{o}{=} \PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{gs}\PY{o}{.}\PY{n}{grid\PYZus{}scores\PYZus{}}
            \PY{k}{if} \PY{n}{x}\PY{o}{.}\PY{n}{parameters}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{degree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}
\PY{n}{gs\PYZus{}deg\PYZus{}3} \PY{o}{=} \PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{gs}\PY{o}{.}\PY{n}{grid\PYZus{}scores\PYZus{}}
            \PY{k}{if} \PY{n}{x}\PY{o}{.}\PY{n}{parameters}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{degree}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{3}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}

\PY{n}{draw\PYZus{}gridscores}\PY{p}{(}\PY{p}{[}\PY{n}{gs\PYZus{}deg\PYZus{}1}\PY{p}{,}  \PY{n}{gs\PYZus{}deg\PYZus{}2}\PY{p}{,} \PY{n}{gs\PYZus{}deg\PYZus{}3}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                 \PY{n}{data\PYZus{}labels}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{1st Order}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                              \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{2nd Order}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{3rd Order}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}
                 \PY{n}{param\PYZus{}label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of Components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                 \PY{n}{score\PYZus{}label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{R\PYZhy{}Squared}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}

\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{homogenization_stress_2D_files/homogenization_stress_2D_31_0.png}
    \end{center}
    { \hspace*{\fill} \\}
Additionally, the model with the optimal parameters can also be
selected using the result from \texttt{GridSeachCV}.
    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{model} \PY{o}{=} \PY{n}{gs}\PY{o}{.}\PY{n}{best\PYZus{}estimator\PYZus{}}

\end{Verbatim}

With our optimized model can now be fit with the calibration data.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\end{Verbatim}

    \subsubsection{Prediction of Effective Stress}\label{prediction-using-mkshomogenizationmodel}

The validation dataset is generate by creating 20 additional
microstructures from the six microstructure classes using the same
\texttt{make\_elastic\_stress\_random} function.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{test\PYZus{}sample\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{20}
\PY{n}{n\PYZus{}samples} \PY{o}{=} \PY{p}{[}\PY{n}{test\PYZus{}sample\PYZus{}size}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{6}
\PY{n}{X\PYZus{}new}\PY{p}{,} \PY{n}{y\PYZus{}new} \PY{o}{=} \PY{n}{make\PYZus{}elastic\PYZus{}stress\PYZus{}random}\PY{p}{(}
    \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n}{n\PYZus{}samples}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{size}\PY{p}{,} \PY{n}{grain\PYZus{}size}\PY{o}{=}\PY{n}{grain\PYZus{}size}\PY{p}{,}
    \PY{n}{elastic\PYZus{}modulus}\PY{o}{=}\PY{n}{elastic\PYZus{}modulus}\PY{p}{,} \PY{n}{poissons\PYZus{}ratio}\PY{o}{=}\PY{n}{poissons\PYZus{}ratio}\PY{p}{,}
    \PY{n}{macro\PYZus{}strain}\PY{o}{=}\PY{n}{macro\PYZus{}strain}\PY{p}{,} \PY{n}{seed}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}

\end{Verbatim}

    The predicted the stress values for the new microstructures are generated using the \texttt{predict} method.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{y\PYZus{}predict} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}new}\PY{p}{)}

\end{Verbatim}

The low-dimensional microstructure descriptors
(see Eq. \ref{eq:struc} and Fig. \ref{fig:workflow})
can be visualized using \texttt{draw\_components\_scatter} from
\texttt{pymks.tools}.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}components\PYZus{}scatter}

\PY{n}{draw\PYZus{}components\PYZus{}scatter}\PY{p}{(}\PY{p}{[}\PY{n}{model}\PY{o}{.}\PY{n}{reduced\PYZus{}fit\PYZus{}data}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{,}
                         \PY{n}{model}\PY{o}{.}\PY{n}{reduced\PYZus{}predict\PYZus{}data}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{]}\PY{p}{,}
                         \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}

\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{homogenization_stress_2D_files/homogenization_stress_2D_41_0.png}
    \end{center}
    { \hspace*{\fill} \\}

The calibration and validation data are samples from the same distributions as expected.
A goodness-of-fit plot provides a visualization of the models performance,
and can be created by importing \texttt{draw\_goodness\_of\_fit} from \texttt{pymks.tools}.

    \begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}goodness\PYZus{}of\PYZus{}fit}

 \PY{n}{fit\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{y}\PY{p}{,} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X}\PY{p}{)}\PY{p}{]}\PY{p}{)}
 \PY{n}{pred\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{y\PYZus{}new}\PY{p}{,} \PY{n}{y\PYZus{}predict}\PY{p}{]}\PY{p}{)}
 \PY{n}{draw\PYZus{}goodness\PYZus{}of\PYZus{}fit}\PY{p}{(}\PY{n}{fit\PYZus{}data}\PY{p}{,} \PY{n}{pred\PYZus{}data}\PY{p}{,}
                      \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Test Data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{homogenization_stress_2D_files/homogenization_stress_2D_47_0.png}
    \end{center}
    { \hspace*{\fill} \\}

\subsection{Prediction of Local Strain Field with Localization}\label{linear-elasticity-in-2d-for-3-phases}


\subsubsection{Calibration Data Generation}\label{generating-calibration-data}


In this example the \texttt{MKSLocalizationModel} used to predict the local
strain field for a three phase microstructure with elastic
moduli values of 80, 100 and 120; Poisson's ratio values all equal to
0.3 and a macroscopic imposed strain equal to 0.02.

The mode is calibrated using delta microstructures for the calibrated
using delta microstructures (analogous to using a unit impulse response
to find the kernel of a system in signal processing). The the material
parameters specified above are used in a finite element simulation
and must be passed into the \texttt{make\_elasticFEstrain\_delta}
function from \texttt{pymks.datasets}. The number of Poisson's
ratio values and elastic moduli values indicates the number of phases.


    \begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}microstructures}
\PY{k+kn}{from} \PY{n+nn}{pymks.datasets} \PY{k+kn}{import} \PY{n}{make\PYZus{}delta\PYZus{}microstructures}
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}

\PY{n}{n} \PY{o}{=} \PY{l+m+mi}{21}
\PY{n}{n\PYZus{}phases} \PY{o}{=} \PY{l+m+mi}{3}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks.datasets} \PY{k+kn}{import} \PY{n}{make\PYZus{}elastic\PYZus{}FE\PYZus{}strain\PYZus{}delta}
\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}microstructure\PYZus{}strain}

\PY{n}{elastic\PYZus{}modulus} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{80}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{120}\PY{p}{)}
\PY{n}{poissons\PYZus{}ratio} \PY{o}{=} \PY{p}{(}\PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
\PY{n}{macro\PYZus{}strain} \PY{o}{=} \PY{l+m+mf}{0.02}
\PY{n}{size} \PY{o}{=} \PY{p}{(}\PY{n}{n}\PY{p}{,} \PY{n}{n}\PY{p}{)}

\PY{n}{X\PYZus{}delta}\PY{p}{,} \PY{n}{strains\PYZus{}delta} \PY{o}{=} \PY{n}{make\PYZus{}elastic\PYZus{}FE\PYZus{}strain\PYZus{}delta}\PY{p}{(}
    \PY{n}{elastic\PYZus{}modulus}\PY{o}{=}\PY{n}{elastic\PYZus{}modulus}\PY{p}{,}
    \PY{n}{poissons\PYZus{}ratio}\PY{o}{=}\PY{n}{poissons\PYZus{}ratio}\PY{p}{,}
    \PY{n}{size}\PY{o}{=}\PY{n}{size}\PY{p}{,} \PY{n}{macro\PYZus{}strain}\PY{o}{=}\PY{n}{macro\PYZus{}strain}\PY{p}{)}

\end{Verbatim}

Delta microstructures are composed of only two phases with the center of the microstructure
being a different phase from the rest. All permutations of thes delta microstructures 
and their associated  strain fields $\varepsilon_{xx}$ are needed to create calibrate
the model. A delta microstructure and it's strain field can be visualized using 
\texttt{draw\_microstructure\_strain} for \texttt{pymks.tools}.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{draw\PYZus{}microstructure\PYZus{}strain}\PY{p}{(}\PY{n}{X\PYZus{}delta}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{strains\PYZus{}delta}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{localization_elasticity_multiphase_2D_files/localization_elasticity_multiphase_2D_11_0.png}
    \end{center}
    { \hspace*{\fill} \\}

\subsubsection{Calibration of the Localization Model}\label{calibrating-first-order-influence-coefficients}


In order to make an instance of the \texttt{MKSHomogenizationModel},
an instance of a basis class must first be created to specify the discretization
methods for the microstructure microstructure function
(see Fig. \ref{fig:workflows}). For this particular example,
there are only 2 discrete phases, therefore the \texttt{PrimitiveBasis}
from \texttt{pymks.bases} will be used. The microstructure contain only two
phases denoted by 0 and 1, therefore we have two local states and our domain
is 0 to 1. An instance of the \texttt{PrimitiveBasis} with these parameters can
be used to create an instance of the \texttt{MKSHomgenizationModel} as follows.

Similar to the \texttt{MKSHomogenizationModel}, an instance
of a basis class to specify the discretization
methods for the microstructure microstructure function
(see Fig. \ref{fig:workflows}).
before an instance of the \texttt{MKSLocalizatoinModel} is created. 
An instance of \texttt{PrimitiveBasis} with \texttt{n\_states} equal to 3,
is used because the material system as 3 distinct phases. 

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks} \PY{k+kn}{import} \PY{n}{MKSLocalizationModel}
\PY{k+kn}{from} \PY{n+nn}{pymks} \PY{k+kn}{import} \PY{n}{PrimitiveBasis}

\PY{n}{p\PYZus{}basis} \PY{o}{=}\PY{n}{PrimitiveBasis}\PY{p}{(}\PY{n}{n\PYZus{}states}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{domain}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
\PY{n}{model} \PY{o}{=} \PY{n}{MKSLocalizationModel}\PY{p}{(}\PY{n}{basis}\PY{o}{=}\PY{n}{p\PYZus{}basis}\PY{p}{)}

\end{Verbatim}

With the delta microstructures and their strain fields, the
the influence kernels can be calibrated using the \texttt{fit} method.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}delta}\PY{p}{,} \PY{n}{strains\PYZus{}delta}\PY{p}{)}

\end{Verbatim}

A visualization of the influence kernels can be generated using the \texttt{draw\_coeff}
function from \texttt{pymks.tools}.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}coeff}

\PY{n}{draw\PYZus{}coeff}\PY{p}{(}\PY{n}{model}\PY{o}{.}\PY{n}{coef\PYZus{}}\PY{p}{)}

\end{Verbatim}
\begin{center}
\adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{localization_elasticity_multiphase_2D_files/localization_elasticity_multiphase_2D_18_0.png}
\end{center}
% { \hspace*{\fill} \\}

\subsubsection{Prediction of the Strain Field for a Random
Microstructure}\label{predict-of-the-strain-field-for-a-random-microstructure}

A predicted strain field from the localization model can be compared 
the strain field using a finite element simulation for the same random
microstructure for model validation. The \texttt{make\_elasticFEstrain\_random} function from
\texttt{pymks.datasets} generates a random
microstructure and its strain field results from finite element
analysis.
    \begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{pymks.datasets} \PY{k+kn}{import} \PY{n}{make\PYZus{}elastic\PYZus{}FE\PYZus{}strain\PYZus{}random}

\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{101}\PY{p}{)}
\PY{n}{X}\PY{p}{,} \PY{n}{strain} \PY{o}{=} \PY{n}{make\PYZus{}elastic\PYZus{}FE\PYZus{}strain\PYZus{}random}\PY{p}{(}
    \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{elastic\PYZus{}modulus}\PY{o}{=}\PY{n}{elastic\PYZus{}modulus}\PY{p}{,}
    \PY{n}{poissons\PYZus{}ratio}\PY{o}{=}\PY{n}{poissons\PYZus{}ratio}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n}{size}\PY{p}{,}
    \PY{n}{macro\PYZus{}strain}\PY{o}{=}\PY{n}{macro\PYZus{}strain}\PY{p}{)}
\PY{n}{draw\PYZus{}microstructure\PYZus{}strain}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{p}{,} \PY{n}{strain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}

\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{localization_elasticity_multiphase_2D_files/localization_elasticity_multiphase_2D_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}


Localization model predicts the strain field by passing the microstructure
to the \texttt{predict} method.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{n}{strain\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X}\PY{p}{)}

\end{Verbatim}

A visualization of the two strain fields from both the localization model and finite element analysis can be created using \texttt{draw\_strains\_compare} from \texttt{pymks.tools}.

    \begin{Verbatim}[commandchars=\\\{\}]

\PY{k+kn}{from} \PY{n+nn}{pymks.tools} \PY{k+kn}{import} \PY{n}{draw\PYZus{}strains\PYZus{}compare}

\PY{n}{draw\PYZus{}strains\PYZus{}compare}\PY{p}{(}\PY{n}{strain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{strain\PYZus{}pred}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}

\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{localization_elasticity_multiphase_2D_files/localization_elasticity_multiphase_2D_25_0.png}
    \end{center}
    { \hspace*{\fill} \\}

\section{Conclusion}


PyMKS is an open source project with a permissive license that provides simple high level APIs to the MKS framework by implementing pipelines from Scikit-learn with customized objects for data from hierarchical materials. PyMKS developers is eager to collaborate with others to grow  an emergent data science community for establishing homogenization and localization Process-Structure-Property linkages for hierarchical materials.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{backmatter}

% \section*{Competing interests}
%   The authors declare that they have no competing interests.

% \section*{Author's contributions}
%     Text for this section \ldots

% \section*{Acknowledgements}
%   Text for this section \ldots
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{bmc_article}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

% \section*{Figures}
%   \begin{figure}[h!]
%   \caption{\csentence{Sample figure title.}
%       A short description of the figure content
%       should go here.}
%       \end{figure}

% \begin{figure}[h!]
%   \caption{\csentence{Sample figure title.}
%       Figure legend text.}
%       \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Tables                        %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Use of \listoftables is discouraged.
%%
% \section*{Tables}
% \begin{table}[h!]
% \caption{Sample table title. This is where the description of the table should go.}
%       \begin{tabular}{cccc}
%         \hline
%           & B1  &B2   & B3\\ \hline
%         A1 & 0.1 & 0.2 & 0.3\\
%         A2 & ... & ..  & .\\
%         A3 & ..  & .   & .\\ \hline
%       \end{tabular}
% \end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Additional Files              %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section*{Additional Files}
%   \subsection*{Additional file 1 --- Sample additional file title}
%     Additional file descriptions text (including details of how to
%     view the file, if it is in a non-standard format or the file extension).  This might
%     refer to a multi-page table or a figure.

%   \subsection*{Additional file 2 --- Sample additional file title}
%     Additional file descriptions text.


% \end{backmatter}
\end{document}
